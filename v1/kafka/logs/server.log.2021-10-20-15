[2021-10-18 13:03:24,523] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 13:03:24,532] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 13:03:24,542] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 13:03:24,542] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 13:03:24,546] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-18 13:03:24,546] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-18 13:03:24,547] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-18 13:03:24,547] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-10-18 13:03:24,554] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-10-18 13:03:24,573] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 13:03:24,573] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 13:03:24,573] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 13:03:24,574] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 13:03:24,574] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-10-18 13:03:24,580] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-10-18 13:03:29,210] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,211] INFO Server environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,211] INFO Server environment:java.version=1.8.0_301 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,211] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,212] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,212] INFO Server environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,215] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,216] INFO Server environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,216] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,216] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,216] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,217] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,217] INFO Server environment:user.name=Pablo Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,217] INFO Server environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,217] INFO Server environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,218] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,218] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,218] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,230] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,230] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,232] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Practica1SD\kafka\data\zookeeper\version-2 snapdir C:\Practica1SD\kafka\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:29,289] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-10-18 13:03:29,298] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-10-18 13:03:29,304] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-10-18 13:03:29,339] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-10-18 13:03:29,368] INFO Reading snapshot C:\Practica1SD\kafka\data\zookeeper\version-2\snapshot.144 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-10-18 13:03:29,432] INFO Snapshotting: 0x169 to C:\Practica1SD\kafka\data\zookeeper\version-2\snapshot.169 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-10-18 13:03:29,460] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2021-10-18 13:03:29,470] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-10-18 13:03:49,024] INFO Expiring session 0x10001cbd0610001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 13:03:49,026] INFO Creating new log file: log.16a (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-10-18 13:03:50,724] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-10-18 13:03:51,222] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-10-18 13:03:51,306] INFO starting (kafka.server.KafkaServer)
[2021-10-18 13:03:51,306] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-10-18 13:03:51,328] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 13:03:55,862] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,863] INFO Client environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,863] INFO Client environment:java.version=1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,863] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,863] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,863] INFO Client environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,882] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,883] INFO Client environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,883] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,883] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,883] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,884] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,884] INFO Client environment:user.name=Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,884] INFO Client environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,884] INFO Client environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,885] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,885] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,885] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,887] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2a3b5b47 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 13:03:55,895] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-10-18 13:03:55,902] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-10-18 13:03:55,905] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 13:03:55,908] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-10-18 13:03:55,910] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52075, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-10-18 13:03:55,933] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005a7786a0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-10-18 13:03:55,935] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 13:03:56,095] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-18 13:03:56,296] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-10-18 13:03:56,301] INFO Cluster ID = fEv9AujaTC2Xq_-BNygJgw (kafka.server.KafkaServer)
[2021-10-18 13:03:56,403] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-18 13:03:56,414] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-18 13:03:56,456] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 13:03:56,457] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 13:03:56,459] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 13:03:56,460] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 13:03:56,506] INFO Loading logs from log dirs ArrayBuffer(C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 13:03:56,510] INFO Attempting recovery for all logs in C:\Practica1SD\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2021-10-18 13:03:56,594] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-18 13:03:56,597] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-18 13:03:56,634] INFO [ProducerStateManager partition=comprobarUsuario-0] Writing producer snapshot at offset 42 (kafka.log.ProducerStateManager)
[2021-10-18 13:03:56,671] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 42 with message format version 2 (kafka.log.Log)
[2021-10-18 13:03:56,672] INFO [ProducerStateManager partition=comprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0\00000000000000000042.snapshot,42)' (kafka.log.ProducerStateManager)
[2021-10-18 13:03:56,685] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0, topic=comprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=42) with 1 segments in 155ms (1/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 13:03:56,691] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-18 13:03:56,691] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-18 13:03:56,699] INFO [ProducerStateManager partition=enviarMapa-0] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2021-10-18 13:03:56,716] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 31 with message format version 2 (kafka.log.Log)
[2021-10-18 13:03:56,716] INFO [ProducerStateManager partition=enviarMapa-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\enviarMapa-0\00000000000000000031.snapshot,31)' (kafka.log.ProducerStateManager)
[2021-10-18 13:03:56,721] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\enviarMapa-0, topic=enviarMapa, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=31) with 1 segments in 35ms (2/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 13:03:56,728] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-18 13:03:56,728] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-18 13:03:56,753] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Writing producer snapshot at offset 667 (kafka.log.ProducerStateManager)
[2021-10-18 13:03:56,771] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 667 with message format version 2 (kafka.log.Log)
[2021-10-18 13:03:56,772] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000667.snapshot,667)' (kafka.log.ProducerStateManager)
[2021-10-18 13:03:56,777] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0, topic=respuestaComprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=667) with 1 segments in 56ms (3/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 13:03:56,779] INFO Loaded 3 logs in 272ms. (kafka.log.LogManager)
[2021-10-18 13:03:56,779] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-10-18 13:03:56,780] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-10-18 13:03:57,289] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-10-18 13:03:57,294] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-10-18 13:03:57,334] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-18 13:03:57,386] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-10-18 13:03:57,409] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 13:03:57,410] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 13:03:57,411] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 13:03:57,412] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 13:03:57,431] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-18 13:04:02,006] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-10-18 13:04:02,029] INFO Stat of the created znode at /brokers/ids/0 is: 378,378,1634555042019,1634555042019,1,0,0,72063810875817984,212,0,378
 (kafka.zk.KafkaZkClient)
[2021-10-18 13:04:02,030] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://Pablo-Bernabeu:9092, czxid (broker epoch): 378 (kafka.zk.KafkaZkClient)
[2021-10-18 13:04:02,107] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 13:04:02,117] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 13:04:02,118] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 13:04:02,137] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-10-18 13:04:02,140] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-10-18 13:04:02,169] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:9000,blockEndProducerId:9999) by writing to Zk with path version 10 (kafka.coordinator.transaction.ProducerIdManager)
[2021-10-18 13:04:02,170] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-18 13:04:02,172] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-18 13:04:02,174] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-10-18 13:04:02,205] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 13:04:02,229] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-10-18 13:04:02,259] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-18 13:04:02,265] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-18 13:04:02,266] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-18 13:04:02,270] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-18 13:04:02,271] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-18 13:04:02,271] INFO Kafka startTimeMs: 1634555042266 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-18 13:04:02,273] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-10-18 13:04:02,318] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker Pablo-Bernabeu:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2021-10-18 13:04:02,321] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(comprobarUsuario-0, respuestaComprobarUsuario-0, enviarMapa-0) (kafka.server.ReplicaFetcherManager)
[2021-10-18 13:04:02,339] INFO [Partition comprobarUsuario-0 broker=0] Log loaded for partition comprobarUsuario-0 with initial high watermark 42 (kafka.cluster.Partition)
[2021-10-18 13:04:02,343] INFO [Partition respuestaComprobarUsuario-0 broker=0] Log loaded for partition respuestaComprobarUsuario-0 with initial high watermark 667 (kafka.cluster.Partition)
[2021-10-18 13:04:02,343] INFO [Partition enviarMapa-0 broker=0] Log loaded for partition enviarMapa-0 with initial high watermark 31 (kafka.cluster.Partition)
[2021-10-18 14:22:54,801] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 14:22:54,811] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 14:22:54,835] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 14:22:54,835] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 14:22:54,836] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-10-18 14:22:54,842] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-18 14:22:54,842] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-18 14:22:54,843] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-18 14:22:54,843] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-10-18 14:22:54,852] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-10-18 14:22:54,877] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 14:22:54,877] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 14:22:54,878] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 14:22:54,878] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-18 14:22:54,878] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-10-18 14:22:54,888] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-10-18 14:22:55,999] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-10-18 14:22:56,132] INFO starting (kafka.server.KafkaServer)
[2021-10-18 14:22:56,133] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-10-18 14:22:56,175] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 14:22:59,434] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,434] INFO Server environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,435] INFO Server environment:java.version=1.8.0_301 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,435] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,435] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,436] INFO Server environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,437] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,437] INFO Server environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,438] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,438] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,438] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,438] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,438] INFO Server environment:user.name=Pablo Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,439] INFO Server environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,439] INFO Server environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,439] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,439] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,439] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,445] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,446] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,446] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Practica1SD\kafka\data\zookeeper\version-2 snapdir C:\Practica1SD\kafka\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:22:59,483] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-10-18 14:22:59,486] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-10-18 14:22:59,489] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-10-18 14:22:59,507] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-10-18 14:22:59,584] INFO Reading snapshot C:\Practica1SD\kafka\data\zookeeper\version-2\snapshot.169 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-10-18 14:22:59,632] INFO Snapshotting: 0x17d to C:\Practica1SD\kafka\data\zookeeper\version-2\snapshot.17d (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-10-18 14:22:59,647] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2021-10-18 14:22:59,652] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-10-18 14:23:00,729] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,729] INFO Client environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,730] INFO Client environment:java.version=1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,730] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,730] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,730] INFO Client environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,747] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,748] INFO Client environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,748] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,748] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,748] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,749] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,749] INFO Client environment:user.name=Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,749] INFO Client environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,749] INFO Client environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,749] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,749] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,749] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,752] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2a3b5b47 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:00,760] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-10-18 14:23:00,768] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-10-18 14:23:00,770] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 14:23:00,777] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-10-18 14:23:00,779] INFO Socket connection established, initiating session, client: /127.0.0.1:54844, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-10-18 14:23:00,785] INFO Creating new log file: log.17e (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-10-18 14:23:00,799] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005f041ff0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-10-18 14:23:00,802] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 14:23:00,972] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-18 14:23:01,189] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-10-18 14:23:01,195] INFO Cluster ID = fEv9AujaTC2Xq_-BNygJgw (kafka.server.KafkaServer)
[2021-10-18 14:23:01,297] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-18 14:23:01,308] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-18 14:23:01,354] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:01,355] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:01,357] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:01,360] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:01,409] INFO Loading logs from log dirs ArrayBuffer(C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 14:23:01,414] INFO Attempting recovery for all logs in C:\Practica1SD\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2021-10-18 14:23:01,506] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-18 14:23:01,506] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-18 14:23:01,537] INFO [ProducerStateManager partition=comprobarUsuario-0] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2021-10-18 14:23:01,568] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2021-10-18 14:23:01,568] INFO [ProducerStateManager partition=comprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0\00000000000000000043.snapshot,43)' (kafka.log.ProducerStateManager)
[2021-10-18 14:23:01,584] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0, topic=comprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=43) with 1 segments in 157ms (1/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 14:23:01,584] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-18 14:23:01,600] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-18 14:23:01,600] INFO [ProducerStateManager partition=enviarMapa-0] Writing producer snapshot at offset 63 (kafka.log.ProducerStateManager)
[2021-10-18 14:23:01,615] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 63 with message format version 2 (kafka.log.Log)
[2021-10-18 14:23:01,615] INFO [ProducerStateManager partition=enviarMapa-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\enviarMapa-0\00000000000000000063.snapshot,63)' (kafka.log.ProducerStateManager)
[2021-10-18 14:23:01,631] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\enviarMapa-0, topic=enviarMapa, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=63) with 1 segments in 38ms (2/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 14:23:01,631] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-18 14:23:01,631] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-18 14:23:01,647] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Writing producer snapshot at offset 710 (kafka.log.ProducerStateManager)
[2021-10-18 14:23:01,678] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 710 with message format version 2 (kafka.log.Log)
[2021-10-18 14:23:01,678] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000710.snapshot,710)' (kafka.log.ProducerStateManager)
[2021-10-18 14:23:01,678] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0, topic=respuestaComprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=710) with 1 segments in 51ms (3/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 14:23:01,678] INFO Loaded 3 logs in 276ms. (kafka.log.LogManager)
[2021-10-18 14:23:01,678] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-10-18 14:23:01,678] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-10-18 14:23:02,225] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-10-18 14:23:02,240] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-10-18 14:23:02,287] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-18 14:23:02,334] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-10-18 14:23:02,350] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:02,350] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:02,350] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:02,350] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:02,365] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-18 14:23:06,951] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-10-18 14:23:06,974] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72063810875817984' does not match current session '72064123495448576' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-10-18 14:23:06,979] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2021-10-18 14:23:06,984] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-10-18 14:23:06,985] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-10-18 14:23:06,990] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-10-18 14:23:06,995] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-10-18 14:23:06,996] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-18 14:23:06,996] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-18 14:23:06,996] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-18 14:23:06,997] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-10-18 14:23:07,006] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-10-18 14:23:07,006] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-10-18 14:23:07,007] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-10-18 14:23:07,007] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,034] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,034] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,035] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,222] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,222] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,223] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,237] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,237] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,237] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,439] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,439] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:07,447] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-10-18 14:23:07,448] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2021-10-18 14:23:07,449] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2021-10-18 14:23:07,449] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-10-18 14:23:07,457] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2021-10-18 14:23:07,458] INFO Shutting down. (kafka.log.LogManager)
[2021-10-18 14:23:07,515] INFO Shutdown complete. (kafka.log.LogManager)
[2021-10-18 14:23:07,515] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-18 14:23:07,516] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-18 14:23:07,516] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-18 14:23:07,517] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 14:23:07,628] INFO Session: 0x10005f041ff0000 closed (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:07,628] INFO EventThread shut down for session: 0x10005f041ff0000 (org.apache.zookeeper.ClientCnxn)
[2021-10-18 14:23:07,630] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 14:23:07,630] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:08,434] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:08,434] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:08,435] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:09,447] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:09,447] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:09,447] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:10,462] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:10,462] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:10,462] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:11,473] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:11,473] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:11,474] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-10-18 14:23:11,501] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2021-10-18 14:23:11,502] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2021-10-18 14:23:11,502] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2021-10-18 14:23:11,502] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2021-10-18 14:23:11,504] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2021-10-18 14:23:11,510] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-18 14:23:11,512] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-10-18 14:23:11,512] ERROR Exiting Kafka. (kafka.Kafka$)
[2021-10-18 14:23:11,513] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-10-18 14:23:14,147] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-10-18 14:23:14,585] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-10-18 14:23:14,646] INFO starting (kafka.server.KafkaServer)
[2021-10-18 14:23:14,647] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-10-18 14:23:14,664] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 14:23:19,023] INFO Expiring session 0x10005a7786a0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-18 14:23:19,200] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,200] INFO Client environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,200] INFO Client environment:java.version=1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,200] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,200] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,200] INFO Client environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,201] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,203] INFO Client environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,203] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,203] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,204] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,204] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,204] INFO Client environment:user.name=Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,204] INFO Client environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,204] INFO Client environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,204] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,205] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,205] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,207] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2a3b5b47 (org.apache.zookeeper.ZooKeeper)
[2021-10-18 14:23:19,223] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-10-18 14:23:19,228] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-10-18 14:23:19,230] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 14:23:19,233] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-10-18 14:23:19,235] INFO Socket connection established, initiating session, client: /127.0.0.1:54861, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-10-18 14:23:19,242] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005f041ff0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-10-18 14:23:19,245] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-18 14:23:19,355] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-18 14:23:19,493] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-10-18 14:23:19,497] INFO Cluster ID = fEv9AujaTC2Xq_-BNygJgw (kafka.server.KafkaServer)
[2021-10-18 14:23:19,576] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-18 14:23:19,587] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-18 14:23:19,621] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:19,622] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:19,624] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:19,625] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-18 14:23:19,660] INFO Loading logs from log dirs ArrayBuffer(C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 14:23:19,664] INFO Skipping recovery for all logs in C:\Practica1SD\kafka\data\kafka since clean shutdown file was found (kafka.log.LogManager)
[2021-10-18 14:23:19,763] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2021-10-18 14:23:19,766] INFO [ProducerStateManager partition=comprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0\00000000000000000043.snapshot,43)' (kafka.log.ProducerStateManager)
[2021-10-18 14:23:19,775] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0, topic=comprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=43) with 1 segments in 93ms (1/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 14:23:19,791] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 63 with message format version 2 (kafka.log.Log)
[2021-10-18 14:23:19,791] INFO [ProducerStateManager partition=enviarMapa-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\enviarMapa-0\00000000000000000063.snapshot,63)' (kafka.log.ProducerStateManager)
[2021-10-18 14:23:19,794] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\enviarMapa-0, topic=enviarMapa, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=63) with 1 segments in 18ms (2/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 14:23:19,810] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 710 with message format version 2 (kafka.log.Log)
[2021-10-18 14:23:19,810] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000710.snapshot,710)' (kafka.log.ProducerStateManager)
[2021-10-18 14:23:19,813] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0, topic=respuestaComprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=710) with 1 segments in 18ms (3/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-18 14:23:19,815] INFO Loaded 3 logs in 154ms. (kafka.log.LogManager)
[2021-10-18 14:23:19,816] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-10-18 14:23:19,817] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-10-18 14:23:20,237] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-10-18 14:23:20,241] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-10-18 14:23:20,295] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-18 14:23:20,338] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-10-18 14:23:20,364] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:20,365] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:20,366] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:20,366] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:20,385] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-18 14:23:25,007] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-10-18 14:23:25,028] INFO Stat of the created znode at /brokers/ids/0 is: 415,415,1634559805015,1634559805015,1,0,0,72064123495448577,212,0,415
 (kafka.zk.KafkaZkClient)
[2021-10-18 14:23:25,029] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://Pablo-Bernabeu:9092, czxid (broker epoch): 415 (kafka.zk.KafkaZkClient)
[2021-10-18 14:23:25,105] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:25,111] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:25,112] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:25,126] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-10-18 14:23:25,130] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-10-18 14:23:25,162] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2021-10-18 14:23:25,163] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-18 14:23:25,166] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-18 14:23:25,167] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-10-18 14:23:25,208] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-18 14:23:25,237] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-10-18 14:23:25,263] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-18 14:23:25,269] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-18 14:23:25,270] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-18 14:23:25,274] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-18 14:23:25,274] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-18 14:23:25,274] INFO Kafka startTimeMs: 1634559805270 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-18 14:23:25,276] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-10-18 14:23:25,327] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(comprobarUsuario-0, respuestaComprobarUsuario-0, enviarMapa-0) (kafka.server.ReplicaFetcherManager)
[2021-10-18 14:23:25,339] INFO [Partition comprobarUsuario-0 broker=0] Log loaded for partition comprobarUsuario-0 with initial high watermark 43 (kafka.cluster.Partition)
[2021-10-18 14:23:25,344] INFO [Partition respuestaComprobarUsuario-0 broker=0] Log loaded for partition respuestaComprobarUsuario-0 with initial high watermark 710 (kafka.cluster.Partition)
[2021-10-18 14:23:25,345] INFO [Partition enviarMapa-0 broker=0] Log loaded for partition enviarMapa-0 with initial high watermark 63 (kafka.cluster.Partition)
[2021-10-18 14:23:25,374] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker Pablo-Bernabeu:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:45:30,023] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:45:30,032] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:45:30,045] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:45:30,046] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:45:30,050] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-20 15:45:30,050] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-20 15:45:30,050] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-20 15:45:30,050] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-10-20 15:45:30,050] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-10-20 15:45:30,057] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-10-20 15:45:30,072] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:45:30,072] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:45:30,073] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:45:30,073] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:45:30,073] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-10-20 15:45:30,079] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-10-20 15:45:31,114] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-10-20 15:45:31,348] INFO starting (kafka.server.KafkaServer)
[2021-10-20 15:45:31,354] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-10-20 15:45:31,472] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:45:34,629] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,629] INFO Server environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,630] INFO Server environment:java.version=1.8.0_301 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,630] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,630] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,630] INFO Server environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,631] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,633] INFO Server environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,633] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,633] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,633] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,634] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,634] INFO Server environment:user.name=Pablo Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,634] INFO Server environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,634] INFO Server environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,634] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,634] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,635] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,642] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,643] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,643] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Practica1SD\kafka\data\zookeeper\version-2 snapdir C:\Practica1SD\kafka\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:45:34,701] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-10-20 15:45:34,707] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-10-20 15:45:34,713] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-10-20 15:45:34,743] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-10-20 15:45:34,860] INFO Reading snapshot C:\Practica1SD\kafka\data\zookeeper\version-2\snapshot.17d (org.apache.zookeeper.server.persistence.FileSnap)
[2021-10-20 15:45:34,927] INFO Snapshotting: 0x1a2 to C:\Practica1SD\kafka\data\zookeeper\version-2\snapshot.1a2 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-10-20 15:45:34,950] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2021-10-20 15:45:34,956] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-10-20 15:45:36,071] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,071] INFO Client environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,071] INFO Client environment:java.version=1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,071] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,071] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,072] INFO Client environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,086] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,088] INFO Client environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,088] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,088] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,088] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,089] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,089] INFO Client environment:user.name=Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,089] INFO Client environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,089] INFO Client environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,089] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,090] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,090] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,093] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2a3b5b47 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:36,112] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-10-20 15:45:36,120] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:45:36,124] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:45:36,127] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:45:36,130] INFO Socket connection established, initiating session, client: /127.0.0.1:51350, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:45:36,138] INFO Creating new log file: log.1a3 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-10-20 15:45:36,159] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1001088e8b30000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:45:36,163] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:45:36,387] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:45:36,897] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-10-20 15:45:36,902] INFO Cluster ID = fEv9AujaTC2Xq_-BNygJgw (kafka.server.KafkaServer)
[2021-10-20 15:45:37,022] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:45:37,031] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:45:37,087] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:37,088] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:37,090] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:37,092] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:37,155] INFO Loading logs from log dirs ArrayBuffer(C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:45:37,163] INFO Attempting recovery for all logs in C:\Practica1SD\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2021-10-20 15:45:37,366] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-20 15:45:37,370] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-20 15:45:37,413] INFO [ProducerStateManager partition=comprobarUsuario-0] Writing producer snapshot at offset 44 (kafka.log.ProducerStateManager)
[2021-10-20 15:45:37,452] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 44 with message format version 2 (kafka.log.Log)
[2021-10-20 15:45:37,452] INFO [ProducerStateManager partition=comprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0\00000000000000000044.snapshot,44)' (kafka.log.ProducerStateManager)
[2021-10-20 15:45:37,464] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0, topic=comprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=44) with 1 segments in 264ms (1/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:45:37,474] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-20 15:45:37,474] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-20 15:45:37,491] INFO [ProducerStateManager partition=enviarMapa-0] Writing producer snapshot at offset 98 (kafka.log.ProducerStateManager)
[2021-10-20 15:45:37,509] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 98 with message format version 2 (kafka.log.Log)
[2021-10-20 15:45:37,509] INFO [ProducerStateManager partition=enviarMapa-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\enviarMapa-0\00000000000000000098.snapshot,98)' (kafka.log.ProducerStateManager)
[2021-10-20 15:45:37,513] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\enviarMapa-0, topic=enviarMapa, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=98) with 1 segments in 46ms (2/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:45:37,518] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-20 15:45:37,519] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-20 15:45:37,566] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Writing producer snapshot at offset 760 (kafka.log.ProducerStateManager)
[2021-10-20 15:45:37,604] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 760 with message format version 2 (kafka.log.Log)
[2021-10-20 15:45:37,605] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000760.snapshot,760)' (kafka.log.ProducerStateManager)
[2021-10-20 15:45:37,620] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0, topic=respuestaComprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=760) with 1 segments in 106ms (3/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:45:37,627] INFO Loaded 3 logs in 472ms. (kafka.log.LogManager)
[2021-10-20 15:45:37,631] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-10-20 15:45:37,635] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-10-20 15:45:38,613] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-10-20 15:45:38,622] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-10-20 15:45:38,671] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-20 15:45:38,727] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:45:38,750] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:38,753] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:38,753] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:38,753] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:38,773] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:45:43,466] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-10-20 15:45:43,499] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72064123495448577' does not match current session '72075774243569664' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-10-20 15:45:43,507] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2021-10-20 15:45:43,511] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-10-20 15:45:43,512] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-10-20 15:45:43,517] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-10-20 15:45:43,523] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-10-20 15:45:43,525] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:45:43,527] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:45:43,527] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:45:43,528] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-10-20 15:45:43,541] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-10-20 15:45:43,545] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-10-20 15:45:43,546] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-10-20 15:45:43,547] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:43,705] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:43,705] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:43,706] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:43,907] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:43,907] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:43,908] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:44,107] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:44,107] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:44,108] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:44,309] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:44,309] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:45:44,327] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-10-20 15:45:44,327] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:45:44,333] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:45:44,333] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:45:44,356] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2021-10-20 15:45:44,364] INFO Shutting down. (kafka.log.LogManager)
[2021-10-20 15:45:44,495] INFO Shutdown complete. (kafka.log.LogManager)
[2021-10-20 15:45:44,496] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:45:44,496] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:45:44,496] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:45:44,499] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:45:44,616] INFO Session: 0x1001088e8b30000 closed (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:45:44,616] INFO EventThread shut down for session: 0x1001088e8b30000 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:45:44,620] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:45:44,622] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:45,162] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:45,162] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:45,163] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:46,172] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:46,172] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:46,174] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:47,175] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:47,175] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:47,175] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:48,181] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:48,181] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:45:48,182] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-10-20 15:45:48,276] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2021-10-20 15:45:48,278] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2021-10-20 15:45:48,278] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2021-10-20 15:45:48,279] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2021-10-20 15:45:48,281] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2021-10-20 15:45:48,281] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:45:48,281] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-10-20 15:45:48,281] ERROR Exiting Kafka. (kafka.Kafka$)
[2021-10-20 15:45:48,281] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-10-20 15:45:55,014] INFO Expiring session 0x10005f041ff0001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:46:39,537] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-10-20 15:46:40,042] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-10-20 15:46:40,133] INFO starting (kafka.server.KafkaServer)
[2021-10-20 15:46:40,134] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-10-20 15:46:40,163] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:46:44,705] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,706] INFO Client environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,706] INFO Client environment:java.version=1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,706] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,706] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,708] INFO Client environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,714] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,718] INFO Client environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,718] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,719] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,719] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,720] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,720] INFO Client environment:user.name=Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,721] INFO Client environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,722] INFO Client environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,722] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,723] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,723] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,728] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2a3b5b47 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:46:44,753] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-10-20 15:46:44,802] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:46:44,814] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:46:44,840] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:46:44,899] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:51395, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:46:44,963] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001088e8b30001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:46:44,984] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:46:45,164] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:46:45,334] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-10-20 15:46:45,341] INFO Cluster ID = fEv9AujaTC2Xq_-BNygJgw (kafka.server.KafkaServer)
[2021-10-20 15:46:45,443] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:46:45,459] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:46:45,504] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:46:45,504] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:46:45,507] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:46:45,508] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:46:45,555] INFO Loading logs from log dirs ArrayBuffer(C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:46:45,559] INFO Skipping recovery for all logs in C:\Practica1SD\kafka\data\kafka since clean shutdown file was found (kafka.log.LogManager)
[2021-10-20 15:46:45,732] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 44 with message format version 2 (kafka.log.Log)
[2021-10-20 15:46:45,736] INFO [ProducerStateManager partition=comprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0\00000000000000000044.snapshot,44)' (kafka.log.ProducerStateManager)
[2021-10-20 15:46:45,786] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0, topic=comprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=44) with 1 segments in 202ms (1/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:46:45,835] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 98 with message format version 2 (kafka.log.Log)
[2021-10-20 15:46:45,836] INFO [ProducerStateManager partition=enviarMapa-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\enviarMapa-0\00000000000000000098.snapshot,98)' (kafka.log.ProducerStateManager)
[2021-10-20 15:46:45,853] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\enviarMapa-0, topic=enviarMapa, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=98) with 1 segments in 65ms (2/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:46:45,910] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 760 with message format version 2 (kafka.log.Log)
[2021-10-20 15:46:45,914] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000760.snapshot,760)' (kafka.log.ProducerStateManager)
[2021-10-20 15:46:45,928] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0, topic=respuestaComprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=760) with 1 segments in 74ms (3/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:46:45,940] INFO Loaded 3 logs in 385ms. (kafka.log.LogManager)
[2021-10-20 15:46:45,943] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-10-20 15:46:45,948] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-10-20 15:46:46,820] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-10-20 15:46:46,840] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-10-20 15:46:47,029] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-20 15:46:47,088] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:46:47,107] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:46:47,108] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:46:47,109] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:46:47,110] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:46:47,124] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:46:51,735] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-10-20 15:46:51,757] INFO Stat of the created znode at /brokers/ids/0 is: 452,452,1634737611747,1634737611747,1,0,0,72075774243569665,212,0,452
 (kafka.zk.KafkaZkClient)
[2021-10-20 15:46:51,758] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://Pablo-Bernabeu:9092, czxid (broker epoch): 452 (kafka.zk.KafkaZkClient)
[2021-10-20 15:46:51,873] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:46:51,897] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:46:51,897] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:46:51,933] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-10-20 15:46:51,942] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-10-20 15:46:51,988] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:11000,blockEndProducerId:11999) by writing to Zk with path version 12 (kafka.coordinator.transaction.ProducerIdManager)
[2021-10-20 15:46:51,991] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-20 15:46:51,996] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-10-20 15:46:51,996] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-20 15:46:52,087] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:46:52,114] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-10-20 15:46:52,178] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-20 15:46:52,198] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-20 15:46:52,199] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-20 15:46:52,208] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:46:52,208] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:46:52,209] INFO Kafka startTimeMs: 1634737612200 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:46:52,211] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-10-20 15:46:52,291] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(comprobarUsuario-0, respuestaComprobarUsuario-0, enviarMapa-0) (kafka.server.ReplicaFetcherManager)
[2021-10-20 15:46:52,304] INFO [Partition comprobarUsuario-0 broker=0] Log loaded for partition comprobarUsuario-0 with initial high watermark 44 (kafka.cluster.Partition)
[2021-10-20 15:46:52,309] INFO [Partition respuestaComprobarUsuario-0 broker=0] Log loaded for partition respuestaComprobarUsuario-0 with initial high watermark 760 (kafka.cluster.Partition)
[2021-10-20 15:46:52,310] INFO [Partition enviarMapa-0 broker=0] Log loaded for partition enviarMapa-0 with initial high watermark 98 (kafka.cluster.Partition)
[2021-10-20 15:46:52,331] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker Pablo-Bernabeu:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:47:19,952] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Rolled new log segment at offset 760 in 4 ms. (kafka.log.Log)
[2021-10-20 15:48:40,502] ERROR Error while rolling log segment for comprobarUsuario-0 in dir C:\Practica1SD\kafka\data\kafka (kafka.server.LogDirFailureChannel)
java.io.IOException: La operacin solicitada no se puede realizar en un archivo con una seccin asignada a usuario abierta
	at java.io.RandomAccessFile.setLength(Native Method)
	at kafka.log.AbstractIndex.$anonfun$resize$1(AbstractIndex.scala:189)
	at kafka.log.AbstractIndex.resize(AbstractIndex.scala:175)
	at kafka.log.TimeIndex.super$resize(TimeIndex.scala:191)
	at kafka.log.TimeIndex.$anonfun$resize$1(TimeIndex.scala:191)
	at kafka.log.TimeIndex.resize(TimeIndex.scala:191)
	at kafka.log.AbstractIndex.$anonfun$trimToValidSize$1(AbstractIndex.scala:241)
	at kafka.log.AbstractIndex.trimToValidSize(AbstractIndex.scala:241)
	at kafka.log.LogSegment.onBecomeInactiveSegment(LogSegment.scala:508)
	at kafka.log.Log.$anonfun$roll$8(Log.scala:2037)
	at kafka.log.Log.$anonfun$roll$8$adapted(Log.scala:2037)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.Log.$anonfun$roll$2(Log.scala:2037)
	at kafka.log.Log.roll(Log.scala:2453)
	at kafka.log.Log.maybeRoll(Log.scala:1988)
	at kafka.log.Log.$anonfun$append$2(Log.scala:1263)
	at kafka.log.Log.append(Log.scala:2453)
	at kafka.log.Log.appendAsLeader(Log.scala:1112)
	at kafka.cluster.Partition.$anonfun$appendRecordsToLeader$1(Partition.scala:1069)
	at kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:1057)
	at kafka.server.ReplicaManager.$anonfun$appendToLocalLog$6(ReplicaManager.scala:958)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
	at scala.collection.mutable.HashMap.$anonfun$foreach$1(HashMap.scala:149)
	at scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)
	at scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:149)
	at scala.collection.TraversableLike.map(TraversableLike.scala:286)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
	at scala.collection.AbstractTraversable.map(Traversable.scala:108)
	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:946)
	at kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:616)
	at kafka.server.KafkaApis.handleProduceRequest(KafkaApis.scala:646)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:167)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:74)
	at java.lang.Thread.run(Unknown Source)
[2021-10-20 15:48:40,509] WARN [ReplicaManager broker=0] Stopping serving replicas in dir C:\Practica1SD\kafka\data\kafka (kafka.server.ReplicaManager)
[2021-10-20 15:48:40,512] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(enviarMapa-0, comprobarUsuario-0, respuestaComprobarUsuario-0) (kafka.server.ReplicaFetcherManager)
[2021-10-20 15:48:40,513] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(enviarMapa-0, comprobarUsuario-0, respuestaComprobarUsuario-0) (kafka.server.ReplicaAlterLogDirsManager)
[2021-10-20 15:48:40,521] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions enviarMapa-0,comprobarUsuario-0,respuestaComprobarUsuario-0 and stopped moving logs for partitions  because they are in the failed log directory C:\Practica1SD\kafka\data\kafka. (kafka.server.ReplicaManager)
[2021-10-20 15:48:40,522] WARN Stopping serving logs in dir C:\Practica1SD\kafka\data\kafka (kafka.log.LogManager)
[2021-10-20 15:48:40,525] ERROR Shutdown broker because all log dirs in C:\Practica1SD\kafka\data\kafka have failed (kafka.log.LogManager)
[2021-10-20 15:48:41,032] WARN Exception causing close of session 0x1001088e8b30001: Se ha forzado la interrupcin de una conexin existente por el host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2021-10-20 15:49:01,024] INFO Expiring session 0x1001088e8b30001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:49:17,198] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-10-20 15:49:17,896] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-10-20 15:49:18,000] INFO starting (kafka.server.KafkaServer)
[2021-10-20 15:49:18,001] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-10-20 15:49:18,029] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:49:22,559] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,560] INFO Client environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,561] INFO Client environment:java.version=1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,561] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,562] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,562] INFO Client environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,637] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,640] INFO Client environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,640] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,641] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,641] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,642] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,642] INFO Client environment:user.name=Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,643] INFO Client environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,643] INFO Client environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,644] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,644] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,645] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,654] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2a3b5b47 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:49:22,694] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-10-20 15:49:22,703] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:49:22,706] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:49:22,712] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:49:22,714] INFO Socket connection established, initiating session, client: /127.0.0.1:57072, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:49:22,723] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1001088e8b30002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:49:22,730] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:49:22,879] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:49:23,125] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-10-20 15:49:23,131] INFO Cluster ID = fEv9AujaTC2Xq_-BNygJgw (kafka.server.KafkaServer)
[2021-10-20 15:49:23,283] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:49:23,300] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:49:23,359] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:49:23,361] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:49:23,363] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:49:23,364] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:49:23,426] INFO Loading logs from log dirs ArrayBuffer(C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:49:23,430] INFO Attempting recovery for all logs in C:\Practica1SD\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2021-10-20 15:49:23,534] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-20 15:49:23,540] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-20 15:49:23,585] INFO [ProducerStateManager partition=comprobarUsuario-0] Writing producer snapshot at offset 44 (kafka.log.ProducerStateManager)
[2021-10-20 15:49:23,630] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 44 with message format version 2 (kafka.log.Log)
[2021-10-20 15:49:23,632] INFO [ProducerStateManager partition=comprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0\00000000000000000044.snapshot,44)' (kafka.log.ProducerStateManager)
[2021-10-20 15:49:23,649] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0, topic=comprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=44) with 1 segments in 198ms (1/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:49:23,656] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-20 15:49:23,657] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-20 15:49:23,681] INFO [ProducerStateManager partition=enviarMapa-0] Writing producer snapshot at offset 131 (kafka.log.ProducerStateManager)
[2021-10-20 15:49:23,705] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 131 with message format version 2 (kafka.log.Log)
[2021-10-20 15:49:23,706] INFO [ProducerStateManager partition=enviarMapa-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\enviarMapa-0\00000000000000000131.snapshot,131)' (kafka.log.ProducerStateManager)
[2021-10-20 15:49:23,714] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\enviarMapa-0, topic=enviarMapa, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=131) with 1 segments in 64ms (2/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:49:23,724] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 760 (kafka.log.Log)
[2021-10-20 15:49:23,725] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 760 with message format version 2 (kafka.log.Log)
[2021-10-20 15:49:23,725] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000760.snapshot,760)' (kafka.log.ProducerStateManager)
[2021-10-20 15:49:23,733] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Writing producer snapshot at offset 804 (kafka.log.ProducerStateManager)
[2021-10-20 15:49:23,757] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 804 with message format version 2 (kafka.log.Log)
[2021-10-20 15:49:23,758] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000804.snapshot,804)' (kafka.log.ProducerStateManager)
[2021-10-20 15:49:23,766] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0, topic=respuestaComprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=804) with 2 segments in 52ms (3/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:49:23,769] INFO Loaded 3 logs in 343ms. (kafka.log.LogManager)
[2021-10-20 15:49:23,770] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-10-20 15:49:23,771] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-10-20 15:49:24,454] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-10-20 15:49:24,460] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-10-20 15:49:24,522] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-20 15:49:24,566] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:49:24,591] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:49:24,592] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:49:24,593] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:49:24,594] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:49:24,610] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:49:29,198] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-10-20 15:49:29,298] INFO Stat of the created znode at /brokers/ids/0 is: 472,472,1634737769207,1634737769207,1,0,0,72075774243569666,212,0,472
 (kafka.zk.KafkaZkClient)
[2021-10-20 15:49:29,300] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://Pablo-Bernabeu:9092, czxid (broker epoch): 472 (kafka.zk.KafkaZkClient)
[2021-10-20 15:49:29,387] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:49:29,393] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:49:29,394] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:49:29,411] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-10-20 15:49:29,416] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-10-20 15:49:29,444] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:12000,blockEndProducerId:12999) by writing to Zk with path version 13 (kafka.coordinator.transaction.ProducerIdManager)
[2021-10-20 15:49:29,445] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-20 15:49:29,450] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-10-20 15:49:29,450] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-20 15:49:29,487] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:49:29,511] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-10-20 15:49:29,539] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-20 15:49:29,545] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-20 15:49:29,546] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-20 15:49:29,550] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:49:29,551] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:49:29,551] INFO Kafka startTimeMs: 1634737769546 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:49:29,553] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-10-20 15:49:29,621] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(comprobarUsuario-0, respuestaComprobarUsuario-0, enviarMapa-0) (kafka.server.ReplicaFetcherManager)
[2021-10-20 15:49:29,642] INFO [Partition comprobarUsuario-0 broker=0] Log loaded for partition comprobarUsuario-0 with initial high watermark 44 (kafka.cluster.Partition)
[2021-10-20 15:49:29,647] INFO [Partition respuestaComprobarUsuario-0 broker=0] Log loaded for partition respuestaComprobarUsuario-0 with initial high watermark 804 (kafka.cluster.Partition)
[2021-10-20 15:49:29,648] INFO [Partition enviarMapa-0 broker=0] Log loaded for partition enviarMapa-0 with initial high watermark 131 (kafka.cluster.Partition)
[2021-10-20 15:49:29,686] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker Pablo-Bernabeu:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:49:40,065] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Rolled new log segment at offset 44 in 15 ms. (kafka.log.Log)
[2021-10-20 15:51:40,890] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:51:40,897] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:51:40,904] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:51:40,904] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:51:40,909] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-20 15:51:40,909] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-20 15:51:40,910] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-10-20 15:51:40,910] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-10-20 15:51:40,915] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-10-20 15:51:40,933] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:51:40,933] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:51:40,934] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:51:40,934] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-10-20 15:51:40,934] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-10-20 15:51:40,939] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-10-20 15:51:42,547] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-10-20 15:51:43,299] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-10-20 15:51:43,401] INFO starting (kafka.server.KafkaServer)
[2021-10-20 15:51:43,402] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-10-20 15:51:43,429] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:51:45,496] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,497] INFO Server environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,498] INFO Server environment:java.version=1.8.0_301 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,499] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,499] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,502] INFO Server environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,520] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,523] INFO Server environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,524] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,524] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,525] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,525] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,526] INFO Server environment:user.name=Pablo Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,526] INFO Server environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,526] INFO Server environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,527] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,528] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,528] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,544] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,544] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,545] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Practica1SD\kafka\data\zookeeper\version-2 snapdir C:\Practica1SD\kafka\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:51:45,565] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-10-20 15:51:45,569] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-10-20 15:51:45,574] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-10-20 15:51:45,602] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-10-20 15:51:45,617] INFO Reading snapshot C:\Practica1SD\kafka\data\zookeeper\version-2\snapshot.1a2 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-10-20 15:51:45,665] INFO Snapshotting: 0x1db to C:\Practica1SD\kafka\data\zookeeper\version-2\snapshot.1db (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-10-20 15:51:45,684] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2021-10-20 15:51:45,691] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-10-20 15:51:47,970] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,970] INFO Client environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,971] INFO Client environment:java.version=1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,971] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,971] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,971] INFO Client environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,988] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,989] INFO Client environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,989] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,989] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,989] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,990] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,990] INFO Client environment:user.name=Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,990] INFO Client environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,990] INFO Client environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,991] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,991] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,991] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:47,995] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2a3b5b47 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:48,007] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-10-20 15:51:48,015] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:51:48,018] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:51:48,024] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:51:48,026] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:57132, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:51:48,036] INFO Creating new log file: log.1dc (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-10-20 15:51:48,058] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100108e90e40000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:51:48,063] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:51:48,246] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:51:48,515] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-10-20 15:51:48,521] INFO Cluster ID = fEv9AujaTC2Xq_-BNygJgw (kafka.server.KafkaServer)
[2021-10-20 15:51:48,656] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:51:48,672] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:51:48,731] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:48,731] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:48,734] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:48,736] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:48,791] INFO Loading logs from log dirs ArrayBuffer(C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:51:48,795] INFO Attempting recovery for all logs in C:\Practica1SD\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2021-10-20 15:51:48,916] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 44 (kafka.log.Log)
[2021-10-20 15:51:48,923] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 44 with message format version 2 (kafka.log.Log)
[2021-10-20 15:51:48,929] INFO [ProducerStateManager partition=comprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0\00000000000000000044.snapshot,44)' (kafka.log.ProducerStateManager)
[2021-10-20 15:51:48,968] INFO [ProducerStateManager partition=comprobarUsuario-0] Writing producer snapshot at offset 45 (kafka.log.ProducerStateManager)
[2021-10-20 15:51:49,014] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 45 with message format version 2 (kafka.log.Log)
[2021-10-20 15:51:49,014] INFO [ProducerStateManager partition=comprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0\00000000000000000045.snapshot,45)' (kafka.log.ProducerStateManager)
[2021-10-20 15:51:49,030] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0, topic=comprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=45) with 2 segments in 212ms (1/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:51:49,043] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2021-10-20 15:51:49,044] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-10-20 15:51:49,081] INFO [ProducerStateManager partition=enviarMapa-0] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2021-10-20 15:51:49,106] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 132 with message format version 2 (kafka.log.Log)
[2021-10-20 15:51:49,107] INFO [ProducerStateManager partition=enviarMapa-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\enviarMapa-0\00000000000000000132.snapshot,132)' (kafka.log.ProducerStateManager)
[2021-10-20 15:51:49,114] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\enviarMapa-0, topic=enviarMapa, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=132) with 1 segments in 82ms (2/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:51:49,127] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Recovering unflushed segment 760 (kafka.log.Log)
[2021-10-20 15:51:49,128] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 760 with message format version 2 (kafka.log.Log)
[2021-10-20 15:51:49,129] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000760.snapshot,760)' (kafka.log.ProducerStateManager)
[2021-10-20 15:51:49,141] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Writing producer snapshot at offset 805 (kafka.log.ProducerStateManager)
[2021-10-20 15:51:49,167] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 805 with message format version 2 (kafka.log.Log)
[2021-10-20 15:51:49,167] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000805.snapshot,805)' (kafka.log.ProducerStateManager)
[2021-10-20 15:51:49,174] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0, topic=respuestaComprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=805) with 2 segments in 60ms (3/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:51:49,176] INFO Loaded 3 logs in 386ms. (kafka.log.LogManager)
[2021-10-20 15:51:49,177] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-10-20 15:51:49,179] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-10-20 15:51:49,904] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-10-20 15:51:49,909] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-10-20 15:51:49,971] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-20 15:51:50,022] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:51:50,059] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:50,065] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:50,065] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:50,065] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:50,154] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:51:54,784] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-10-20 15:51:54,815] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72075774243569666' does not match current session '72075798540189696' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-10-20 15:51:54,827] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2021-10-20 15:51:54,830] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-10-20 15:51:54,831] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-10-20 15:51:54,836] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-10-20 15:51:54,842] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-10-20 15:51:54,843] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:51:54,844] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:51:54,844] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:51:54,845] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-10-20 15:51:54,847] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-10-20 15:51:54,848] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-10-20 15:51:54,848] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-10-20 15:51:54,849] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:54,972] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:54,972] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:54,974] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:55,159] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:55,159] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:55,161] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:55,360] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:55,360] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:55,362] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:55,561] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:55,561] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:51:55,579] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-10-20 15:51:55,581] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:51:55,583] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:51:55,584] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:51:55,598] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2021-10-20 15:51:55,602] INFO Shutting down. (kafka.log.LogManager)
[2021-10-20 15:51:55,726] INFO Shutdown complete. (kafka.log.LogManager)
[2021-10-20 15:51:55,727] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:51:55,727] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:51:55,727] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:51:55,729] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:51:55,847] INFO Session: 0x100108e90e40000 closed (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:51:55,847] INFO EventThread shut down for session: 0x100108e90e40000 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:51:55,850] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:51:55,851] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:56,783] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:56,783] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:56,784] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:57,786] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:57,786] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:57,786] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:57,801] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:57,801] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:57,801] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:58,806] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:58,806] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:51:58,811] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-10-20 15:51:58,851] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2021-10-20 15:51:58,852] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2021-10-20 15:51:58,853] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2021-10-20 15:51:58,853] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2021-10-20 15:51:58,856] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2021-10-20 15:51:58,860] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:51:58,861] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-10-20 15:51:58,861] ERROR Exiting Kafka. (kafka.Kafka$)
[2021-10-20 15:51:58,862] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-10-20 15:52:03,554] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-10-20 15:52:04,013] INFO Expiring session 0x1001088e8b30002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-10-20 15:52:04,061] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-10-20 15:52:04,216] INFO starting (kafka.server.KafkaServer)
[2021-10-20 15:52:04,217] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-10-20 15:52:04,251] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:52:08,798] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,799] INFO Client environment:host.name=Pablo-Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,800] INFO Client environment:java.version=1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,800] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,800] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_301 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,802] INFO Client environment:java.class.path=C:\Practica1SD\kafka\libs\activation-1.1.1.jar;C:\Practica1SD\kafka\libs\aopalliance-repackaged-2.6.1.jar;C:\Practica1SD\kafka\libs\argparse4j-0.7.0.jar;C:\Practica1SD\kafka\libs\audience-annotations-0.5.0.jar;C:\Practica1SD\kafka\libs\commons-cli-1.4.jar;C:\Practica1SD\kafka\libs\commons-lang3-3.8.1.jar;C:\Practica1SD\kafka\libs\connect-api-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-basic-auth-extension-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-file-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-json-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-mirror-client-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-runtime-2.8.0.jar;C:\Practica1SD\kafka\libs\connect-transforms-2.8.0.jar;C:\Practica1SD\kafka\libs\hk2-api-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-locator-2.6.1.jar;C:\Practica1SD\kafka\libs\hk2-utils-2.6.1.jar;C:\Practica1SD\kafka\libs\jackson-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-core-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-databind-2.10.5.1.jar;C:\Practica1SD\kafka\libs\jackson-dataformat-csv-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-base-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-paranamer-2.10.5.jar;C:\Practica1SD\kafka\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Practica1SD\kafka\libs\jakarta.activation-api-1.2.1.jar;C:\Practica1SD\kafka\libs\jakarta.annotation-api-1.3.5.jar;C:\Practica1SD\kafka\libs\jakarta.inject-2.6.1.jar;C:\Practica1SD\kafka\libs\jakarta.validation-api-2.0.2.jar;C:\Practica1SD\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Practica1SD\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Practica1SD\kafka\libs\javassist-3.27.0-GA.jar;C:\Practica1SD\kafka\libs\javax.servlet-api-3.1.0.jar;C:\Practica1SD\kafka\libs\javax.ws.rs-api-2.1.1.jar;C:\Practica1SD\kafka\libs\jaxb-api-2.3.0.jar;C:\Practica1SD\kafka\libs\jersey-client-2.31.jar;C:\Practica1SD\kafka\libs\jersey-common-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-2.31.jar;C:\Practica1SD\kafka\libs\jersey-container-servlet-core-2.31.jar;C:\Practica1SD\kafka\libs\jersey-hk2-2.31.jar;C:\Practica1SD\kafka\libs\jersey-media-jaxb-2.31.jar;C:\Practica1SD\kafka\libs\jersey-server-2.31.jar;C:\Practica1SD\kafka\libs\jetty-client-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-http-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-io-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-security-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-server-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Practica1SD\kafka\libs\jline-3.12.1.jar;C:\Practica1SD\kafka\libs\jopt-simple-5.0.4.jar;C:\Practica1SD\kafka\libs\kafka-clients-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-log4j-appender-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-metadata-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-raft-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-shell-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-examples-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-streams-test-utils-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka-tools-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar;C:\Practica1SD\kafka\libs\kafka_2.12-2.8.0.jar.asc;C:\Practica1SD\kafka\libs\log4j-1.2.17.jar;C:\Practica1SD\kafka\libs\lz4-java-1.7.1.jar;C:\Practica1SD\kafka\libs\maven-artifact-3.6.3.jar;C:\Practica1SD\kafka\libs\metrics-core-2.2.0.jar;C:\Practica1SD\kafka\libs\netty-buffer-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-codec-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-handler-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-resolver-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Practica1SD\kafka\libs\osgi-resource-locator-1.0.3.jar;C:\Practica1SD\kafka\libs\paranamer-2.8.jar;C:\Practica1SD\kafka\libs\plexus-utils-3.2.1.jar;C:\Practica1SD\kafka\libs\reflections-0.9.12.jar;C:\Practica1SD\kafka\libs\rocksdbjni-5.18.4.jar;C:\Practica1SD\kafka\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Practica1SD\kafka\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Practica1SD\kafka\libs\scala-library-2.12.13.jar;C:\Practica1SD\kafka\libs\scala-logging_2.12-3.9.2.jar;C:\Practica1SD\kafka\libs\scala-reflect-2.12.13.jar;C:\Practica1SD\kafka\libs\slf4j-api-1.7.30.jar;C:\Practica1SD\kafka\libs\slf4j-log4j12-1.7.30.jar;C:\Practica1SD\kafka\libs\snappy-java-1.1.8.1.jar;C:\Practica1SD\kafka\libs\zookeeper-3.5.9.jar;C:\Practica1SD\kafka\libs\zookeeper-jute-3.5.9.jar;C:\Practica1SD\kafka\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,833] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\Program Files\VMWare\bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\AutoFirma\AutoFirma;C:\Program Files\Git\cmd;C:\speccpu2000\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Python\Python39\;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;D:\Pablo Bernabeu\w64devkit\bin;C:\Users\Pablo Bernabeu\.dotnet\tools;C:\Users\Pablo Bernabeu\AppData\Local\Programs\Microsoft VS Code\bin;C:\Practica1SD\kafka\bin\windows;C:\Users\Pablo Bernabeu\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,835] INFO Client environment:java.io.tmpdir=C:\Users\PABLOB~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,836] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,837] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,837] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,837] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,839] INFO Client environment:user.name=Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,839] INFO Client environment:user.home=C:\Users\Pablo Bernabeu (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,839] INFO Client environment:user.dir=C:\Practica1SD\kafka (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,839] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,840] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,841] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,848] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2a3b5b47 (org.apache.zookeeper.ZooKeeper)
[2021-10-20 15:52:08,860] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-10-20 15:52:08,868] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:52:08,871] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:52:08,875] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:52:08,878] INFO Socket connection established, initiating session, client: /127.0.0.1:57149, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:52:08,888] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100108e90e40001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-10-20 15:52:08,893] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-10-20 15:52:09,031] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-10-20 15:52:09,205] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-10-20 15:52:09,209] INFO Cluster ID = fEv9AujaTC2Xq_-BNygJgw (kafka.server.KafkaServer)
[2021-10-20 15:52:09,287] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:52:09,298] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Practica1SD/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-10-20 15:52:09,331] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:52:09,331] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:52:09,334] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:52:09,334] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-10-20 15:52:09,369] INFO Loading logs from log dirs ArrayBuffer(C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:52:09,372] INFO Skipping recovery for all logs in C:\Practica1SD\kafka\data\kafka since clean shutdown file was found (kafka.log.LogManager)
[2021-10-20 15:52:09,516] INFO [Log partition=comprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 45 with message format version 2 (kafka.log.Log)
[2021-10-20 15:52:09,519] INFO [ProducerStateManager partition=comprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0\00000000000000000045.snapshot,45)' (kafka.log.ProducerStateManager)
[2021-10-20 15:52:09,528] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\comprobarUsuario-0, topic=comprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=45) with 2 segments in 118ms (1/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:52:09,546] INFO [Log partition=enviarMapa-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 132 with message format version 2 (kafka.log.Log)
[2021-10-20 15:52:09,546] INFO [ProducerStateManager partition=enviarMapa-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\enviarMapa-0\00000000000000000132.snapshot,132)' (kafka.log.ProducerStateManager)
[2021-10-20 15:52:09,551] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\enviarMapa-0, topic=enviarMapa, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=132) with 1 segments in 22ms (2/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:52:09,573] INFO [Log partition=respuestaComprobarUsuario-0, dir=C:\Practica1SD\kafka\data\kafka] Loading producer state till offset 805 with message format version 2 (kafka.log.Log)
[2021-10-20 15:52:09,573] INFO [ProducerStateManager partition=respuestaComprobarUsuario-0] Loading producer state from snapshot file 'SnapshotFile(C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0\00000000000000000805.snapshot,805)' (kafka.log.ProducerStateManager)
[2021-10-20 15:52:09,576] INFO Completed load of Log(dir=C:\Practica1SD\kafka\data\kafka\respuestaComprobarUsuario-0, topic=respuestaComprobarUsuario, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=805) with 2 segments in 24ms (3/3 loaded in C:\Practica1SD\kafka\data\kafka) (kafka.log.LogManager)
[2021-10-20 15:52:09,578] INFO Loaded 3 logs in 209ms. (kafka.log.LogManager)
[2021-10-20 15:52:09,579] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-10-20 15:52:09,580] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-10-20 15:52:10,100] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-10-20 15:52:10,116] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-10-20 15:52:10,176] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-20 15:52:10,210] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:52:10,233] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:52:10,234] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:52:10,235] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:52:10,235] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:52:10,250] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-10-20 15:52:14,849] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-10-20 15:52:14,879] INFO Stat of the created znode at /brokers/ids/0 is: 509,509,1634737934868,1634737934868,1,0,0,72075798540189697,212,0,509
 (kafka.zk.KafkaZkClient)
[2021-10-20 15:52:14,879] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://Pablo-Bernabeu:9092, czxid (broker epoch): 509 (kafka.zk.KafkaZkClient)
[2021-10-20 15:52:14,969] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:52:14,974] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:52:14,975] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:52:14,990] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-10-20 15:52:14,997] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-10-20 15:52:15,025] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:13000,blockEndProducerId:13999) by writing to Zk with path version 14 (kafka.coordinator.transaction.ProducerIdManager)
[2021-10-20 15:52:15,026] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-20 15:52:15,031] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-10-20 15:52:15,031] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-10-20 15:52:15,067] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-10-20 15:52:15,136] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-10-20 15:52:15,177] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-20 15:52:15,184] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-10-20 15:52:15,184] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-10-20 15:52:15,188] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:52:15,188] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:52:15,188] INFO Kafka startTimeMs: 1634737935184 (org.apache.kafka.common.utils.AppInfoParser)
[2021-10-20 15:52:15,190] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-10-20 15:52:15,215] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker Pablo-Bernabeu:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2021-10-20 15:52:15,244] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(comprobarUsuario-0, respuestaComprobarUsuario-0, enviarMapa-0) (kafka.server.ReplicaFetcherManager)
[2021-10-20 15:52:15,257] INFO [Partition comprobarUsuario-0 broker=0] Log loaded for partition comprobarUsuario-0 with initial high watermark 45 (kafka.cluster.Partition)
[2021-10-20 15:52:15,260] INFO [Partition respuestaComprobarUsuario-0 broker=0] Log loaded for partition respuestaComprobarUsuario-0 with initial high watermark 805 (kafka.cluster.Partition)
[2021-10-20 15:52:15,261] INFO [Partition enviarMapa-0 broker=0] Log loaded for partition enviarMapa-0 with initial high watermark 132 (kafka.cluster.Partition)
